{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/neuralangelo-colab/blob/main/neuralangelo_colab.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "\n",
        "!apt-get install \\\n",
        "    cmake \\\n",
        "    libgoogle-glog-dev \\\n",
        "    libgflags-dev \\\n",
        "    libatlas-base-dev \\\n",
        "    libeigen3-dev \\\n",
        "    libsuitesparse-dev \\\n",
        "    libboost-program-options-dev \\\n",
        "    libboost-filesystem-dev \\\n",
        "    libboost-graph-dev \\\n",
        "    libboost-system-dev \\\n",
        "    libboost-test-dev \\\n",
        "    libfreeimage-dev \\\n",
        "    libmetis-dev \\\n",
        "    libglew-dev \\\n",
        "    qtbase5-dev \\\n",
        "    libqt5opengl5-dev \\\n",
        "    libcgal-dev\n",
        "\n",
        "!wget https://huggingface.co/camenduru/neuralangelo/resolve/main/colmap.zip\n",
        "!unzip /content/colmap.zip -d colmap\n",
        "\n",
        "!cp -r /content/colmap/lib/. /usr/local/lib\n",
        "!chmod 755 /content/colmap/bin/colmap\n",
        "!cp -r /content/colmap/bin/. /usr/local/bin\n",
        "\n",
        "!pip install -q commentjson addict pynvml wandb trimesh PyMCubes\n",
        "!pip install -q https://huggingface.co/camenduru/CoDeF/resolve/main/tinycudann-1.7-cp310-cp310-linux_x86_64.whl\n",
        "\n",
        "%cd /content\n",
        "!git clone -b v1.0 --recursive https://github.com/camenduru/neuralangelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/neuralangelo\n",
        "!wget https://huggingface.co/camenduru/neuralangelo/resolve/main/lego.mp4 -O /content/lego.mp4\n",
        "SEQUENCE=\"lego\"\n",
        "PATH_TO_VIDEO=\"/content/lego.mp4\"\n",
        "DOWNSAMPLE_RATE=2\n",
        "SCENE_TYPE=\"object\"\n",
        "!bash /content/neuralangelo/projects/neuralangelo/scripts/preprocess.sh {SEQUENCE} {PATH_TO_VIDEO} {DOWNSAMPLE_RATE} {SCENE_TYPE}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from https://github.com/NVlabs/neuralangelo\n",
        "# @title Visulize COLMAP (Optional)\n",
        "!pip install -q k3d\n",
        "\n",
        "colmap_path='/content/neuralangelo/datasets/lego_ds2'\n",
        "%cd /content/neuralangelo\n",
        "# Import Python libraries.\n",
        "import numpy as np\n",
        "import torch\n",
        "import k3d\n",
        "import json\n",
        "import plotly.graph_objs as go\n",
        "from collections import OrderedDict\n",
        "# Import imaginaire modules.\n",
        "from projects.nerf.utils import camera, visualize\n",
        "from third_party.colmap.scripts.python.read_write_model import read_model\n",
        "# Read the COLMAP data.\n",
        "cameras, images, points_3D = read_model(path=f\"{colmap_path}/sparse\", ext=\".bin\")\n",
        "# Convert camera poses.\n",
        "images = OrderedDict(sorted(images.items()))\n",
        "qvecs = torch.from_numpy(np.stack([image.qvec for image in images.values()]))\n",
        "tvecs = torch.from_numpy(np.stack([image.tvec for image in images.values()]))\n",
        "Rs = camera.quaternion.q_to_R(qvecs)\n",
        "poses = torch.cat([Rs, tvecs[..., None]], dim=-1)  # [N,3,4]\n",
        "print(f\"# images: {len(poses)}\")\n",
        "# Get the sparse 3D points and the colors.\n",
        "xyzs = torch.from_numpy(np.stack([point.xyz for point in points_3D.values()]))\n",
        "rgbs = np.stack([point.rgb for point in points_3D.values()])\n",
        "rgbs_int32 = (rgbs[:, 0] * 2**16 + rgbs[:, 1] * 2**8 + rgbs[:, 2]).astype(np.uint32)\n",
        "print(f\"# points: {len(xyzs)}\")\n",
        "\n",
        "# Visualize the bounding sphere.\n",
        "json_fname = f\"{colmap_path}/transforms.json\"\n",
        "with open(json_fname) as file:\n",
        "    meta = json.load(file)\n",
        "center = meta[\"sphere_center\"]\n",
        "radius = meta[\"sphere_radius\"]\n",
        "# ------------------------------------------------------------------------------------\n",
        "# These variables can be adjusted to make the bounding sphere fit the region of interest.\n",
        "# The adjusted values can then be set in the config as data.readjust.center and data.readjust.scale\n",
        "readjust_x = 0.  # @param {type:\"number\"}\n",
        "readjust_y = 0.  # @param {type:\"number\"}\n",
        "readjust_z = 0.  # @param {type:\"number\"}\n",
        "readjust_scale = 1.  # @param {type:\"number\"}\n",
        "readjust_center = np.array([readjust_x, readjust_y, readjust_z])\n",
        "# ------------------------------------------------------------------------------------\n",
        "center += readjust_center\n",
        "radius *= readjust_scale\n",
        "# Make some points to hallucinate a bounding sphere.\n",
        "sphere_points = np.random.randn(100000, 3)\n",
        "sphere_points = sphere_points / np.linalg.norm(sphere_points, axis=-1, keepdims=True)\n",
        "sphere_points = sphere_points * radius + center\n",
        "\n",
        "vis_depth = 0.2\n",
        "# Visualize with Plotly.\n",
        "x, y, z = *xyzs.T,\n",
        "colors = rgbs / 255.0\n",
        "sphere_x, sphere_y, sphere_z = *sphere_points.T,\n",
        "sphere_colors = [\"#4488ff\"] * len(sphere_points)\n",
        "traces_poses = visualize.plotly_visualize_pose(poses, vis_depth=vis_depth, xyz_length=0.02, center_size=0.01, xyz_width=0.005, mesh_opacity=0.05)\n",
        "trace_points = go.Scatter3d(x=x, y=y, z=z, mode=\"markers\", marker=dict(size=1, color=colors, opacity=1), hoverinfo=\"skip\")\n",
        "trace_sphere = go.Scatter3d(x=sphere_x, y=sphere_y, z=sphere_z, mode=\"markers\", marker=dict(size=0.5, color=sphere_colors, opacity=0.7), hoverinfo=\"skip\")\n",
        "traces_all = traces_poses + [trace_points, trace_sphere]\n",
        "layout = go.Layout(scene=dict(xaxis=dict(showspikes=False, backgroundcolor=\"rgba(0,0,0,0)\", gridcolor=\"rgba(0,0,0,0.1)\"),\n",
        "                              yaxis=dict(showspikes=False, backgroundcolor=\"rgba(0,0,0,0)\", gridcolor=\"rgba(0,0,0,0.1)\"),\n",
        "                              zaxis=dict(showspikes=False, backgroundcolor=\"rgba(0,0,0,0)\", gridcolor=\"rgba(0,0,0,0.1)\"),\n",
        "                              xaxis_title=\"X\", yaxis_title=\"Y\", zaxis_title=\"Z\", dragmode=\"orbit\",\n",
        "                              aspectratio=dict(x=1, y=1, z=1), aspectmode=\"data\"), height=800)\n",
        "fig = go.Figure(data=traces_all, layout=layout)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/neuralangelo\n",
        "EXPERIMENT=\"lego\"\n",
        "GROUP=\"lego_group\"\n",
        "NAME=\"lego\"\n",
        "CONFIG=f\"/content/neuralangelo/projects/neuralangelo/configs/custom/{EXPERIMENT}.yaml\"\n",
        "GPUS=1\n",
        "CHECKPOINT_PATH=\"/content/checkpoint\"\n",
        "!torchrun --nproc_per_node={GPUS} train.py \\\n",
        "    --wandb \\\n",
        "    --wandb_name=neuralangelo \\\n",
        "    --logdir=logs/{GROUP}/{NAME} \\\n",
        "    --config={CONFIG} \\\n",
        "    --show_pbar \\\n",
        "    --data.readjust.scale=0.5 \\\n",
        "    --max_iter=25000 \\\n",
        "    --model.object.sdf.encoding.coarse2fine.step=200 \\\n",
        "    --model.object.sdf.encoding.hashgrid.dict_size=19 \\\n",
        "    --optim.sched.warm_up_end=200 \\\n",
        "    --optim.sched.two_steps=[12000,16000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/neuralangelo\n",
        "CONFIG=f\"/content/neuralangelo/projects/neuralangelo/configs/custom/lego.yaml\"\n",
        "GPUS=1\n",
        "CHECKPOINT=\"/content/neuralangelo/logs/lego_group/lego/epoch_00150_iteration_000015000_checkpoint.pt\"\n",
        "OUTPUT_MESH=\"/content/lego.ply\"\n",
        "RESOLUTION=2048\n",
        "BLOCK_RES=128\n",
        "!torchrun --nproc_per_node={GPUS} projects/neuralangelo/scripts/extract_mesh.py \\\n",
        "    --config={CONFIG} \\\n",
        "    --checkpoint={CHECKPOINT} \\\n",
        "    --output_file={OUTPUT_MESH} \\\n",
        "    --resolution={RESOLUTION} \\\n",
        "    --block_res={BLOCK_RES} \\\n",
        "    --textured"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
